{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH9St0Tn9rEuHkSqzJ1V73",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hajar-lyoubi/AI54_TD_Tutorials/blob/main/TD3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TD 03 - Exercises - Word Embeddings**\n"
      ],
      "metadata": {
        "id": "q_wqBginll7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # *0- Basics of neural networks with PyTorch*"
      ],
      "metadata": {
        "id": "laYScQclmnkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this section, we build a simple neural network to understand the basic workflow in PyTorch:\n",
        "- loading a dataset,\n",
        "- defining a model,\n",
        "- training it, and\n",
        "- evaluating its accuracy.\n",
        "\n",
        "The dataset `height_weight_sex_training_set.csv` contains people’s height, weight, and sex.  \n",
        "The goal is to predict whether a person is **male** or **female** based on height and weight.\n"
      ],
      "metadata": {
        "id": "Hf6clURjm5Lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 — Importing libraries\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_5tlqWaopF4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data as tud\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "id": "wolcDgOimbpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 — Loading and inspecting the dataset  \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TUDwYAMApiHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('height_weight_sex_training_set.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CwwQ2HG5pZfF",
        "outputId": "cbf6c7a4-33f9-4e4d-f9be-bb23c7f86b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height  Weight     Sex\n",
              "0  165.65   35.41  Female\n",
              "1  148.53   74.45  Female\n",
              "2  167.04   81.22    Male\n",
              "3  161.54   71.47    Male\n",
              "4  174.31   78.18    Male"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d31575e2-06fd-4ab9-b688-410d21fefcbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165.65</td>\n",
              "      <td>35.41</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>148.53</td>\n",
              "      <td>74.45</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>167.04</td>\n",
              "      <td>81.22</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>161.54</td>\n",
              "      <td>71.47</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>174.31</td>\n",
              "      <td>78.18</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d31575e2-06fd-4ab9-b688-410d21fefcbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d31575e2-06fd-4ab9-b688-410d21fefcbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d31575e2-06fd-4ab9-b688-410d21fefcbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a917d03f-6c3f-4b9f-b4a3-65e2f36e7e57\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a917d03f-6c3f-4b9f-b4a3-65e2f36e7e57')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a917d03f-6c3f-4b9f-b4a3-65e2f36e7e57 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54.91271856414176,\n        \"min\": 25.68,\n        \"max\": 3050.0,\n        \"num_unique_values\": 2330,\n        \"samples\": [\n          146.89,\n          140.33,\n          125.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.041527655001246,\n        \"min\": 8.53,\n        \"max\": 485.0,\n        \"num_unique_values\": 2310,\n        \"samples\": [\n          93.04,\n          49.18,\n          89.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset looks correct: each row corresponds to one individual with their height, weight, and gender.  \n",
        "Next, we will prepare the data to be used as input tensors for the neural network.\n"
      ],
      "metadata": {
        "id": "lTDStu63qEO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 — Preparing the input data  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In this step, we prepare the **inputs** (features) for the neural network.  \n",
        "We extract the columns `Height` and `Weight` from the dataset and convert them into PyTorch tensors of type `float32`.  \n",
        "Each individual is represented by a vector of size 2 → `[height, weight]`.\n",
        "\n",
        "We use the function `unsqueeze(1)` to add an extra dimension, making sure the data has the right shape for concatenation.  \n",
        "Finally, we concatenate both tensors into a single input matrix.\n"
      ],
      "metadata": {
        "id": "RNJXeyZBqiID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the inputs (we want a list of vectors of size 2)\n",
        "heights = torch.tensor(df['Height'], dtype=torch.float32).unsqueeze(1)\n",
        "weights = torch.tensor(df['Weight'], dtype=torch.float32).unsqueeze(1)\n",
        "inputs = torch.cat((heights, weights), dim=1)\n"
      ],
      "metadata": {
        "id": "89OvNaPmp58c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 — Preparing the output data  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Next, we prepare the **outputs** (labels) for training.  \n",
        "The column `Sex` contains categorical values ('Male' or 'Female'),  \n",
        "so we replace these strings by numeric labels: 0 for *Female* and 1 for *Male*."
      ],
      "metadata": {
        "id": "nu87IslOqzoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the outputs (we want 1-hot encoded values for the two possible classes)\n",
        "outputs = F.one_hot(torch.tensor(df['Sex'].replace('Female', 0).replace('Male', 1))).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVajMsrXqpzC",
        "outputId": "a6505150-79dc-451b-98cb-0afe0c067a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-47438714.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  outputs = F.one_hot(torch.tensor(df['Sex'].replace('Female', 0).replace('Male', 1))).float()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 — Defining the neural network model  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this step, we define a very simple neural network using PyTorch.  \n",
        "The model is **sequential**, meaning each layer feeds its output to the next one.  \n",
        "\n",
        "- The **input layer** receives 2 values (height and weight).  \n",
        "- The **hidden layer** has 16 neurons with a linear transformation followed by a ReLU activation (implicitly handled later).  \n",
        "- The **output layer** has 2 neurons, one for each possible category: *Male* or *Female*.  \n"
      ],
      "metadata": {
        "id": "CajUHnhZrZ7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model (i.e. the neural network)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 16),\n",
        "    nn.Linear(16, 2)\n",
        ")"
      ],
      "metadata": {
        "id": "DK3U3CLxq7KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6 — Training the neural network  \n",
        "\n",
        "\n",
        "---\n",
        "Now that the model is defined, we can train it using the prepared data.  \n",
        "We define:\n",
        "- **Loss function:** `CrossEntropyLoss()` — compares predicted classes with true labels.  \n",
        "- **Optimizer:** `Adam` — adjusts weights to minimize the loss function.  \n",
        "\n",
        "The training loop runs for several epochs (iterations).  \n",
        "At each epoch:\n",
        "1. The model predicts the outputs (`logits`),\n",
        "2. The loss is computed,\n",
        "3. The gradients are backpropagated,\n",
        "4. The optimizer updates the model parameters.\n",
        "\n",
        "We print the loss every 10 epochs to monitor convergence.\n"
      ],
      "metadata": {
        "id": "YFpVTKv9rsJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 2000\n",
        "for epoch in range(1, epochs + 1):\n",
        "  logits = model(inputs)                # The model is applied on all the inputs\n",
        "  loss = criterion(logits, outputs)     # The error is computed for all the predictions (logits) according to expected outputs\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # Every 10 step we print the epoch and the loss so we can see the training\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ufzMHFrnO5",
        "outputId": "a2749675-3dc8-495d-c98c-7ea4a8e24fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.8577123284339905\n",
            "Epoch: 20, Loss: 1.0777045488357544\n",
            "Epoch: 30, Loss: 0.4793497622013092\n",
            "Epoch: 40, Loss: 0.5959108471870422\n",
            "Epoch: 50, Loss: 0.5192997455596924\n",
            "Epoch: 60, Loss: 0.4882560968399048\n",
            "Epoch: 70, Loss: 0.47098231315612793\n",
            "Epoch: 80, Loss: 0.46969014406204224\n",
            "Epoch: 90, Loss: 0.4675212502479553\n",
            "Epoch: 100, Loss: 0.46719974279403687\n",
            "Epoch: 110, Loss: 0.466734915971756\n",
            "Epoch: 120, Loss: 0.46631932258605957\n",
            "Epoch: 130, Loss: 0.4659329950809479\n",
            "Epoch: 140, Loss: 0.46551135182380676\n",
            "Epoch: 150, Loss: 0.46510863304138184\n",
            "Epoch: 160, Loss: 0.46470406651496887\n",
            "Epoch: 170, Loss: 0.4643022119998932\n",
            "Epoch: 180, Loss: 0.46390438079833984\n",
            "Epoch: 190, Loss: 0.4635111391544342\n",
            "Epoch: 200, Loss: 0.46312370896339417\n",
            "Epoch: 210, Loss: 0.46274250745773315\n",
            "Epoch: 220, Loss: 0.46236860752105713\n",
            "Epoch: 230, Loss: 0.4620024859905243\n",
            "Epoch: 240, Loss: 0.4616447389125824\n",
            "Epoch: 250, Loss: 0.46129584312438965\n",
            "Epoch: 260, Loss: 0.4609562158584595\n",
            "Epoch: 270, Loss: 0.46062612533569336\n",
            "Epoch: 280, Loss: 0.46030595898628235\n",
            "Epoch: 290, Loss: 0.45999568700790405\n",
            "Epoch: 300, Loss: 0.4596957564353943\n",
            "Epoch: 310, Loss: 0.45940613746643066\n",
            "Epoch: 320, Loss: 0.45912671089172363\n",
            "Epoch: 330, Loss: 0.458857923746109\n",
            "Epoch: 340, Loss: 0.45861268043518066\n",
            "Epoch: 350, Loss: 0.5552481412887573\n",
            "Epoch: 360, Loss: 0.6333736181259155\n",
            "Epoch: 370, Loss: 0.5014371871948242\n",
            "Epoch: 380, Loss: 0.4789230227470398\n",
            "Epoch: 390, Loss: 0.49234598875045776\n",
            "Epoch: 400, Loss: 0.4609547555446625\n",
            "Epoch: 410, Loss: 0.5045050978660583\n",
            "Epoch: 420, Loss: 0.4698698818683624\n",
            "Epoch: 430, Loss: 0.5127128958702087\n",
            "Epoch: 440, Loss: 0.46573367714881897\n",
            "Epoch: 450, Loss: 0.521148681640625\n",
            "Epoch: 460, Loss: 0.4597284197807312\n",
            "Epoch: 470, Loss: 0.47549647092819214\n",
            "Epoch: 480, Loss: 0.46226999163627625\n",
            "Epoch: 490, Loss: 0.5022392868995667\n",
            "Epoch: 500, Loss: 0.4989568591117859\n",
            "Epoch: 510, Loss: 0.4808702766895294\n",
            "Epoch: 520, Loss: 0.4830198884010315\n",
            "Epoch: 530, Loss: 0.4845910668373108\n",
            "Epoch: 540, Loss: 0.45703333616256714\n",
            "Epoch: 550, Loss: 0.48961833119392395\n",
            "Epoch: 560, Loss: 0.4690898358821869\n",
            "Epoch: 570, Loss: 0.46496233344078064\n",
            "Epoch: 580, Loss: 0.5147849321365356\n",
            "Epoch: 590, Loss: 0.4896557331085205\n",
            "Epoch: 600, Loss: 0.4635419547557831\n",
            "Epoch: 610, Loss: 0.4640432894229889\n",
            "Epoch: 620, Loss: 0.512039840221405\n",
            "Epoch: 630, Loss: 0.4769017696380615\n",
            "Epoch: 640, Loss: 0.48020878434181213\n",
            "Epoch: 650, Loss: 0.4659402668476105\n",
            "Epoch: 660, Loss: 0.5120809078216553\n",
            "Epoch: 670, Loss: 0.4562220573425293\n",
            "Epoch: 680, Loss: 0.45588552951812744\n",
            "Epoch: 690, Loss: 0.46035313606262207\n",
            "Epoch: 700, Loss: 0.49167218804359436\n",
            "Epoch: 710, Loss: 0.4963121712207794\n",
            "Epoch: 720, Loss: 0.4584282636642456\n",
            "Epoch: 730, Loss: 0.4563972055912018\n",
            "Epoch: 740, Loss: 0.4611131548881531\n",
            "Epoch: 750, Loss: 0.4707528054714203\n",
            "Epoch: 760, Loss: 0.4582122266292572\n",
            "Epoch: 770, Loss: 0.4653358459472656\n",
            "Epoch: 780, Loss: 0.5154117345809937\n",
            "Epoch: 790, Loss: 0.4615761339664459\n",
            "Epoch: 800, Loss: 0.5287197828292847\n",
            "Epoch: 810, Loss: 0.45720675587654114\n",
            "Epoch: 820, Loss: 0.4556337893009186\n",
            "Epoch: 830, Loss: 0.4911586046218872\n",
            "Epoch: 840, Loss: 0.45537739992141724\n",
            "Epoch: 850, Loss: 0.4652593731880188\n",
            "Epoch: 860, Loss: 0.4660816788673401\n",
            "Epoch: 870, Loss: 0.45830559730529785\n",
            "Epoch: 880, Loss: 0.45961955189704895\n",
            "Epoch: 890, Loss: 0.45590800046920776\n",
            "Epoch: 900, Loss: 0.4596213698387146\n",
            "Epoch: 910, Loss: 0.4696328938007355\n",
            "Epoch: 920, Loss: 0.4553263485431671\n",
            "Epoch: 930, Loss: 0.4576731324195862\n",
            "Epoch: 940, Loss: 0.5320562124252319\n",
            "Epoch: 950, Loss: 0.45757585763931274\n",
            "Epoch: 960, Loss: 0.45861804485321045\n",
            "Epoch: 970, Loss: 0.5556552410125732\n",
            "Epoch: 980, Loss: 0.45540565252304077\n",
            "Epoch: 990, Loss: 0.5233940482139587\n",
            "Epoch: 1000, Loss: 0.45535990595817566\n",
            "Epoch: 1010, Loss: 0.520237922668457\n",
            "Epoch: 1020, Loss: 0.45614710450172424\n",
            "Epoch: 1030, Loss: 0.4640754759311676\n",
            "Epoch: 1040, Loss: 0.499337375164032\n",
            "Epoch: 1050, Loss: 0.46288618445396423\n",
            "Epoch: 1060, Loss: 0.5120716094970703\n",
            "Epoch: 1070, Loss: 0.4616227149963379\n",
            "Epoch: 1080, Loss: 0.4911577105522156\n",
            "Epoch: 1090, Loss: 0.4693855047225952\n",
            "Epoch: 1100, Loss: 0.47495755553245544\n",
            "Epoch: 1110, Loss: 0.4836167097091675\n",
            "Epoch: 1120, Loss: 0.46938931941986084\n",
            "Epoch: 1130, Loss: 0.4924840033054352\n",
            "Epoch: 1140, Loss: 0.46935734152793884\n",
            "Epoch: 1150, Loss: 0.48746025562286377\n",
            "Epoch: 1160, Loss: 0.4731874465942383\n",
            "Epoch: 1170, Loss: 0.4793749153614044\n",
            "Epoch: 1180, Loss: 0.47884634137153625\n",
            "Epoch: 1190, Loss: 0.475029855966568\n",
            "Epoch: 1200, Loss: 0.4817686080932617\n",
            "Epoch: 1210, Loss: 0.4744925796985626\n",
            "Epoch: 1220, Loss: 0.4803740680217743\n",
            "Epoch: 1230, Loss: 0.47623875737190247\n",
            "Epoch: 1240, Loss: 0.4777121841907501\n",
            "Epoch: 1250, Loss: 0.47816401720046997\n",
            "Epoch: 1260, Loss: 0.47626030445098877\n",
            "Epoch: 1270, Loss: 0.47860515117645264\n",
            "Epoch: 1280, Loss: 0.4763106405735016\n",
            "Epoch: 1290, Loss: 0.47777098417282104\n",
            "Epoch: 1300, Loss: 0.47701478004455566\n",
            "Epoch: 1310, Loss: 0.47685346007347107\n",
            "Epoch: 1320, Loss: 0.4774211347103119\n",
            "Epoch: 1330, Loss: 0.47651171684265137\n",
            "Epoch: 1340, Loss: 0.477223664522171\n",
            "Epoch: 1350, Loss: 0.476639986038208\n",
            "Epoch: 1360, Loss: 0.4767777919769287\n",
            "Epoch: 1370, Loss: 0.4767955243587494\n",
            "Epoch: 1380, Loss: 0.47647348046302795\n",
            "Epoch: 1390, Loss: 0.4767378270626068\n",
            "Epoch: 1400, Loss: 0.4764034152030945\n",
            "Epoch: 1410, Loss: 0.4764888882637024\n",
            "Epoch: 1420, Loss: 0.47642919421195984\n",
            "Epoch: 1430, Loss: 0.47627222537994385\n",
            "Epoch: 1440, Loss: 0.47634634375572205\n",
            "Epoch: 1450, Loss: 0.47617900371551514\n",
            "Epoch: 1460, Loss: 0.47618037462234497\n",
            "Epoch: 1470, Loss: 0.4761255979537964\n",
            "Epoch: 1480, Loss: 0.4760282039642334\n",
            "Epoch: 1490, Loss: 0.4760253429412842\n",
            "Epoch: 1500, Loss: 0.4759224057197571\n",
            "Epoch: 1510, Loss: 0.4758998155593872\n",
            "Epoch: 1520, Loss: 0.47583863139152527\n",
            "Epoch: 1530, Loss: 0.4757705628871918\n",
            "Epoch: 1540, Loss: 0.47574567794799805\n",
            "Epoch: 1550, Loss: 0.4756659269332886\n",
            "Epoch: 1560, Loss: 0.47562524676322937\n",
            "Epoch: 1570, Loss: 0.47557592391967773\n",
            "Epoch: 1580, Loss: 0.47551870346069336\n",
            "Epoch: 1590, Loss: 0.4754698872566223\n",
            "Epoch: 1600, Loss: 0.4754239618778229\n",
            "Epoch: 1610, Loss: 0.47536560893058777\n",
            "Epoch: 1620, Loss: 0.47532105445861816\n",
            "Epoch: 1630, Loss: 0.47527599334716797\n",
            "Epoch: 1640, Loss: 0.4752161502838135\n",
            "Epoch: 1650, Loss: 0.47517576813697815\n",
            "Epoch: 1660, Loss: 0.47512102127075195\n",
            "Epoch: 1670, Loss: 0.47507479786872864\n",
            "Epoch: 1680, Loss: 0.4750363826751709\n",
            "Epoch: 1690, Loss: 0.4749760627746582\n",
            "Epoch: 1700, Loss: 0.47494491934776306\n",
            "Epoch: 1710, Loss: 0.4748774766921997\n",
            "Epoch: 1720, Loss: 0.4748423993587494\n",
            "Epoch: 1730, Loss: 0.4747978150844574\n",
            "Epoch: 1740, Loss: 0.47475335001945496\n",
            "Epoch: 1750, Loss: 0.47469469904899597\n",
            "Epoch: 1760, Loss: 0.4746653735637665\n",
            "Epoch: 1770, Loss: 0.47461849451065063\n",
            "Epoch: 1780, Loss: 0.4745629131793976\n",
            "Epoch: 1790, Loss: 0.4745296239852905\n",
            "Epoch: 1800, Loss: 0.47448018193244934\n",
            "Epoch: 1810, Loss: 0.4744405150413513\n",
            "Epoch: 1820, Loss: 0.4743959605693817\n",
            "Epoch: 1830, Loss: 0.47434720396995544\n",
            "Epoch: 1840, Loss: 0.4743129014968872\n",
            "Epoch: 1850, Loss: 0.47426196932792664\n",
            "Epoch: 1860, Loss: 0.4742274582386017\n",
            "Epoch: 1870, Loss: 0.47417688369750977\n",
            "Epoch: 1880, Loss: 0.4741399884223938\n",
            "Epoch: 1890, Loss: 0.4740998148918152\n",
            "Epoch: 1900, Loss: 0.47405049204826355\n",
            "Epoch: 1910, Loss: 0.4740203320980072\n",
            "Epoch: 1920, Loss: 0.473975270986557\n",
            "Epoch: 1930, Loss: 0.473926305770874\n",
            "Epoch: 1940, Loss: 0.473903089761734\n",
            "Epoch: 1950, Loss: 0.4738472104072571\n",
            "Epoch: 1960, Loss: 0.4738093614578247\n",
            "Epoch: 1970, Loss: 0.473783940076828\n",
            "Epoch: 1980, Loss: 0.4737235903739929\n",
            "Epoch: 1990, Loss: 0.47369271516799927\n",
            "Epoch: 2000, Loss: 0.47367045283317566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7 — Observing the results\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "During training, the loss gradually decreases, showing that the model is learning to classify the data correctly.  \n",
        "After enough epochs, the loss should stabilize around a small value (close to 0), indicating good performance.  \n",
        "\n",
        "This confirms that the network can differentiate between male and female based on height and weight.\n"
      ],
      "metadata": {
        "id": "6slpsJgJr--i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8 — Manual evaluation (single examples)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In this step, we manually test the trained neural network on a few custom examples.\n",
        "Each example represents a person defined by their height and weight.\n",
        "The model predicts the probability of belonging to each class (Female / Male).\n",
        "We use the softmax function to visualize the predicted probabilities."
      ],
      "metadata": {
        "id": "3CjjSnAQwG3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Manual checks ---\n",
        "idx2label = {0: \"Female\", 1: \"Male\"}\n",
        "\n",
        "def predict_one(h, w):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.tensor([h, w], dtype=torch.float32)\n",
        "        p = F.softmax(model(x), dim=0)\n",
        "        return idx2label[int(p.argmax())], p.tolist()\n",
        "\n",
        "samples = [(150,60), (170,75), (185,85), (160,50), (175,68)]\n",
        "for h,w in samples:\n",
        "    lab, probs = predict_one(h,w)\n",
        "    print(f\"H={h}, W={w} -> {lab}  (P(F)={probs[0]:.2f}, P(M)={probs[1]:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqgWwwRos6re",
        "outputId": "4f563c33-7297-4ce1-896b-246a7f6243a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H=150, W=60 -> Female  (P(F)=0.72, P(M)=0.28)\n",
            "H=170, W=75 -> Male  (P(F)=0.14, P(M)=0.86)\n",
            "H=185, W=85 -> Male  (P(F)=0.02, P(M)=0.98)\n",
            "H=160, W=50 -> Female  (P(F)=0.61, P(M)=0.39)\n",
            "H=175, W=68 -> Male  (P(F)=0.12, P(M)=0.88)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8 — Evaluate on the test dataset\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Finally, we evaluate the model on a separate test set (height_weight_sex_test_set.csv).\n",
        "This step helps measure generalization — how well the model performs on new, unseen data.\n",
        "We compute:\n",
        "\n",
        "the accuracy (overall correct predictions),\n",
        "\n",
        "and the confusion matrix (errors by class)."
      ],
      "metadata": {
        "id": "lbY0VJNpwWhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test set evaluation ---\n",
        "df_test = pd.read_csv(\"height_weight_sex_test_set.csv\")\n",
        "\n",
        "X_test = torch.tensor(df_test[['Height','Weight']].values, dtype=torch.float32)\n",
        "y_test = torch.tensor(df_test['Sex'].replace({'Female':0,'Male':1}).values, dtype=torch.long)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test).argmax(dim=1)\n",
        "\n",
        "acc = accuracy_score(y_test.numpy(), preds.numpy())\n",
        "cm  = confusion_matrix(y_test.numpy(), preds.numpy(), labels=[0,1])\n",
        "print(f\"Test accuracy: {acc*100:.2f}%\")\n",
        "print(\"Confusion matrix (rows=true, cols=pred):\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6RMvK5ovYwd",
        "outputId": "7aa9e895-7b7c-446e-e5e7-c94d2eeaaf90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 84.88%\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            " [[76 23]\n",
            " [ 8 98]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2156402400.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_test = torch.tensor(df_test['Sex'].replace({'Female':0,'Male':1}).values, dtype=torch.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieves about 85 % accuracy on the test set, which is a good result for such a simple neural network.\n",
        "\n",
        "The confusion matrix shows that most misclassifications happen for individuals with intermediate height and weight, where the two classes overlap.\n",
        "\n",
        "Overall, the model correctly captures the relationship between size and gender using only two input features."
      ],
      "metadata": {
        "id": "MrMSHJyQwqpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # *1- Word2Vec CBOW*"
      ],
      "metadata": {
        "id": "J_fE3Gb2wwOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 — Importing libraries and Selecting the right device can speed up the computation\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ORbwksxiyAtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import random\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPq-hd_jwisb",
        "outputId": "b15aac32-87f6-4adb-9d01-89ece3b0a8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use the GPU if available\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvyvt05ByJdX",
        "outputId": "e3a91bf8-487f-4694-9c7f-55c96cf2697e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 - Loading and inspecting the dataset\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6h74-23Iyghd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('romeo_and_juliet.txt') as file:\n",
        "  content = file.read()"
      ],
      "metadata": {
        "id": "2wjCcgNYyW-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 : Normalization, tokenization using NLTK, stopword removal and generate a vocabulary\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fgK2o_qNy1z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing of the text\n",
        "content = content.lower()\n",
        "tokens = word_tokenize(content)\n",
        "\n",
        "# Remove punctuation\n",
        "tokens = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "print(tokens[0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmZ0Gz6-ywXA",
        "outputId": "f3e9153a-f05e-40a0-c352-76f9f05016df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'tragedy', 'of', 'romeo', 'and', 'juliet', 'by', 'william', 'shakespeare', 'dramatis', 'personae', 'chorus', 'escalus', 'prince', 'of', 'verona', 'paris', 'a', 'young', 'count', 'kinsman', 'to', 'the', 'prince', 'montague', 'heads', 'of', 'two', 'houses', 'at', 'variance', 'with', 'each', 'other', 'capulet', 'heads', 'of', 'two', 'houses', 'at', 'variance', 'with', 'each', 'other', 'an', 'old', 'man', 'of', 'the', 'capulet', 'family', 'romeo', 'son', 'to', 'montague', 'tybalt', 'nephew', 'to', 'lady', 'capulet', 'mercutio', 'kinsman', 'to', 'the', 'prince', 'and', 'friend', 'to', 'romeo', 'benvolio', 'nephew', 'to', 'montague', 'and', 'friend', 'to', 'romeo', 'tybalt', 'nephew', 'to', 'lady', 'capulet', 'friar', 'laurence', 'franciscan', 'friar', 'john', 'franciscan', 'balthasar', 'servant', 'to', 'romeo', 'abram', 'servant', 'to', 'montague', 'sampson', 'servant', 'to', 'capulet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a vocabulary and a dictionary so we have indices for each word\n",
        "vocabulary = list(set(tokens))\n",
        "\n",
        "word2idx = {}\n",
        "for i in range(len(vocabulary)):\n",
        "  word2idx[vocabulary[i]] = i\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocabulary)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s95JdFMAzGYQ",
        "outputId": "237ba225-9633-4f45-b28f-f7f49b5fc9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 3464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 — Build CBOW dataset (window = 2)\n",
        "\n",
        "For each position *t*, target = `tokens[t]`, context = tokens at `t-2, t-1, t+1, t+2`.\n",
        "We store indices for efficiency.\n"
      ],
      "metadata": {
        "id": "x-3qvH1X0pR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the dataset\n",
        "target_word_ids = []\n",
        "context_words_ids = []\n",
        "\n",
        "for position in range(2, len(tokens) - 2):\n",
        "  target_word_ids.append(word2idx[tokens[position]])\n",
        "  context_words_ids.append([\n",
        "      word2idx[tokens[position-2]],\n",
        "      word2idx[tokens[position-1]],\n",
        "      word2idx[tokens[position+1]],\n",
        "      word2idx[tokens[position+2]]\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "YukBxRWazaT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 — Model (Embedding → sum → Linear → logits)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gYRphkEA0sSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Word2Vec CBOW module\n",
        "class Word2VecCBOW(nn.Module):\n",
        "  def __init__(self, vocabulary_size, embedding_dim):\n",
        "    super(Word2VecCBOW, self).__init__()\n",
        "    # An embedding layer, to reduce the size of vectors from vocabulary size to the embedding dimension\n",
        "    self.embeddings = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "    # An output layer, to have the probabilities for each target words from the embedding\n",
        "    self.linear = nn.Linear(embedding_dim, vocabulary_size, bias=False)\n",
        "\n",
        "  def forward(self, context):\n",
        "    # Computing the embedding for the context words\n",
        "    embed = self.embeddings(context)\n",
        "    # Make an aggregation\n",
        "    sum_embed = torch.sum(embed, dim=1)\n",
        "    # Compute the output\n",
        "    out = self.linear(sum_embed)\n",
        "\n",
        "    return out\n",
        "\n",
        "word2vec_cbow = Word2VecCBOW(len(vocabulary), 128).to(device)"
      ],
      "metadata": {
        "id": "-FkzDkAGzf-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(word2vec_cbow.parameters())"
      ],
      "metadata": {
        "id": "0nX5SsFmzj2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6 — Training\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We iterate over the corpus in batches (here, simple contiguous slices).\n",
        "We report the mean loss per epoch.\n"
      ],
      "metadata": {
        "id": "sHvy0zJT00oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model (it can be really slow, there is no optimization here except training with batches)\n",
        "losses = []\n",
        "\n",
        "for epoch in range(100):\n",
        "  batch_size = 2000 # We compute the loss on batches of 2000 elements, to speed up the training process\n",
        "  for position in range(0, len(tokens) - batch_size, batch_size):\n",
        "    batch_input = context_words_ids[position:position + batch_size]\n",
        "    batch_output = target_word_ids[position:position + batch_size]\n",
        "\n",
        "    prediction = word2vec_cbow(torch.tensor(batch_input, device=device))\n",
        "    loss = criterion(prediction, torch.tensor(batch_output, device=device))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  print(f'Epoch #{epoch}, avg loss {torch.mean(torch.tensor(losses)).item()}')\n",
        "  losses.clear()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh4pLm6Pzqyl",
        "outputId": "e2de1272-97de-4688-e088-41e407b2d3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0, avg loss 8.676487922668457\n",
            "Epoch #1, avg loss 8.115889549255371\n",
            "Epoch #2, avg loss 7.654500484466553\n",
            "Epoch #3, avg loss 7.230898380279541\n",
            "Epoch #4, avg loss 6.841434001922607\n",
            "Epoch #5, avg loss 6.491261959075928\n",
            "Epoch #6, avg loss 6.1837477684021\n",
            "Epoch #7, avg loss 5.915843486785889\n",
            "Epoch #8, avg loss 5.68001127243042\n",
            "Epoch #9, avg loss 5.469067096710205\n",
            "Epoch #10, avg loss 5.278133392333984\n",
            "Epoch #11, avg loss 5.103716850280762\n",
            "Epoch #12, avg loss 4.943240165710449\n",
            "Epoch #13, avg loss 4.794861793518066\n",
            "Epoch #14, avg loss 4.6572651863098145\n",
            "Epoch #15, avg loss 4.529474258422852\n",
            "Epoch #16, avg loss 4.410709857940674\n",
            "Epoch #17, avg loss 4.300286293029785\n",
            "Epoch #18, avg loss 4.197551727294922\n",
            "Epoch #19, avg loss 4.101866245269775\n",
            "Epoch #20, avg loss 4.012605667114258\n",
            "Epoch #21, avg loss 3.9291696548461914\n",
            "Epoch #22, avg loss 3.8509960174560547\n",
            "Epoch #23, avg loss 3.7775652408599854\n",
            "Epoch #24, avg loss 3.7084054946899414\n",
            "Epoch #25, avg loss 3.643094301223755\n",
            "Epoch #26, avg loss 3.5812528133392334\n",
            "Epoch #27, avg loss 3.52254581451416\n",
            "Epoch #28, avg loss 3.466677665710449\n",
            "Epoch #29, avg loss 3.413384437561035\n",
            "Epoch #30, avg loss 3.362434148788452\n",
            "Epoch #31, avg loss 3.3136215209960938\n",
            "Epoch #32, avg loss 3.266761064529419\n",
            "Epoch #33, avg loss 3.221691370010376\n",
            "Epoch #34, avg loss 3.178265333175659\n",
            "Epoch #35, avg loss 3.1363532543182373\n",
            "Epoch #36, avg loss 3.0958378314971924\n",
            "Epoch #37, avg loss 3.056614637374878\n",
            "Epoch #38, avg loss 3.0185906887054443\n",
            "Epoch #39, avg loss 2.9816792011260986\n",
            "Epoch #40, avg loss 2.945805788040161\n",
            "Epoch #41, avg loss 2.9108998775482178\n",
            "Epoch #42, avg loss 2.876899003982544\n",
            "Epoch #43, avg loss 2.843747138977051\n",
            "Epoch #44, avg loss 2.8113911151885986\n",
            "Epoch #45, avg loss 2.7797844409942627\n",
            "Epoch #46, avg loss 2.7488839626312256\n",
            "Epoch #47, avg loss 2.71864914894104\n",
            "Epoch #48, avg loss 2.689044952392578\n",
            "Epoch #49, avg loss 2.6600377559661865\n",
            "Epoch #50, avg loss 2.631596565246582\n",
            "Epoch #51, avg loss 2.6036932468414307\n",
            "Epoch #52, avg loss 2.5763020515441895\n",
            "Epoch #53, avg loss 2.549398183822632\n",
            "Epoch #54, avg loss 2.522960662841797\n",
            "Epoch #55, avg loss 2.496967315673828\n",
            "Epoch #56, avg loss 2.471400022506714\n",
            "Epoch #57, avg loss 2.4462411403656006\n",
            "Epoch #58, avg loss 2.421473741531372\n",
            "Epoch #59, avg loss 2.3970820903778076\n",
            "Epoch #60, avg loss 2.3730533123016357\n",
            "Epoch #61, avg loss 2.3493731021881104\n",
            "Epoch #62, avg loss 2.3260293006896973\n",
            "Epoch #63, avg loss 2.3030104637145996\n",
            "Epoch #64, avg loss 2.2803053855895996\n",
            "Epoch #65, avg loss 2.257904529571533\n",
            "Epoch #66, avg loss 2.2357981204986572\n",
            "Epoch #67, avg loss 2.213977813720703\n",
            "Epoch #68, avg loss 2.1924350261688232\n",
            "Epoch #69, avg loss 2.1711618900299072\n",
            "Epoch #70, avg loss 2.150151491165161\n",
            "Epoch #71, avg loss 2.129396915435791\n",
            "Epoch #72, avg loss 2.1088919639587402\n",
            "Epoch #73, avg loss 2.088630437850952\n",
            "Epoch #74, avg loss 2.0686070919036865\n",
            "Epoch #75, avg loss 2.048816442489624\n",
            "Epoch #76, avg loss 2.0292532444000244\n",
            "Epoch #77, avg loss 2.009913682937622\n",
            "Epoch #78, avg loss 1.9907926321029663\n",
            "Epoch #79, avg loss 1.9718860387802124\n",
            "Epoch #80, avg loss 1.9531902074813843\n",
            "Epoch #81, avg loss 1.9347013235092163\n",
            "Epoch #82, avg loss 1.9164155721664429\n",
            "Epoch #83, avg loss 1.8983300924301147\n",
            "Epoch #84, avg loss 1.8804411888122559\n",
            "Epoch #85, avg loss 1.862746238708496\n",
            "Epoch #86, avg loss 1.845241904258728\n",
            "Epoch #87, avg loss 1.8279260396957397\n",
            "Epoch #88, avg loss 1.8107951879501343\n",
            "Epoch #89, avg loss 1.7938475608825684\n",
            "Epoch #90, avg loss 1.7770808935165405\n",
            "Epoch #91, avg loss 1.7604926824569702\n",
            "Epoch #92, avg loss 1.7440805435180664\n",
            "Epoch #93, avg loss 1.7278428077697754\n",
            "Epoch #94, avg loss 1.7117775678634644\n",
            "Epoch #95, avg loss 1.6958829164505005\n",
            "Epoch #96, avg loss 1.6801570653915405\n",
            "Epoch #97, avg loss 1.6645983457565308\n",
            "Epoch #98, avg loss 1.649205207824707\n",
            "Epoch #99, avg loss 1.6339761018753052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7 — Finding the most similar words in the embedding space\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Once the model is trained, each word is represented by a vector (its embedding).  \n",
        "Words that appear in **similar contexts** end up with **similar embeddings**.\n",
        "\n",
        "To verify that, we:\n",
        "1. extract the embedding matrix from the model,\n",
        "2. normalize all vectors (so cosine similarity = dot product),\n",
        "3. select a specific word (e.g. `\"man\"`),\n",
        "4. compute its similarity with every other word,\n",
        "5. print the **10 most similar words**.\n"
      ],
      "metadata": {
        "id": "oCWzCZ5k1Yj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # Disable the computation of gradients (useful for evaluation)\n",
        "  # The weights of the embedding matrix are the embeddings of all words (the line #0 is embedding of word #0, etc.)\n",
        "  embeddings = word2vec_cbow.embeddings.weight.detach()\n",
        "  # Here we normalize the embeddings to be able to compute the cosine similarity by taking the dot product of embeddings\n",
        "  normalized_embeddings = embeddings / torch.norm(embeddings, p=2, dim=1, keepdim=True)\n",
        "\n",
        "  embedding = normalized_embeddings[word2idx['man']]\n",
        "\n",
        "  # Efficiently compute the dot product of all lines of normalized_embeddings with embedding\n",
        "  similarities = torch.mv(normalized_embeddings, embedding)\n",
        "\n",
        "  # Get the 10 top indices (discard the values)\n",
        "  _, top10 = torch.topk(similarities, 10, largest=True, sorted=True)\n",
        "\n",
        "  print([vocabulary[idx.item()] for idx in top10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB1DusQbztPP",
        "outputId": "195cdda1-44a6-458c-b388-92085b4ebec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['man', 'tainted', 'toad', 'unadvis', 'conjur', 'sparkling', 'obscur', 'departed', 'mood', 'measure']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # *2- Word2Vec Skipgrams*"
      ],
      "metadata": {
        "id": "dPbZRlLB1lKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 — Build the Skip-gram dataset\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sG0i2DQq5rBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window = 2\n",
        "centers, targets = [], []\n",
        "\n",
        "for t in range(window, len(tokens) - window):\n",
        "    c = word2idx[tokens[t]]\n",
        "    ctxs = [word2idx[tokens[t - 2]],\n",
        "            word2idx[tokens[t - 1]],\n",
        "            word2idx[tokens[t + 1]],\n",
        "            word2idx[tokens[t + 2]]]\n",
        "    for u in ctxs:\n",
        "        centers.append(c)\n",
        "        targets.append(u)\n",
        "\n",
        "len(centers), len(targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v45gNDNY1gBy",
        "outputId": "6ac4fc63-b564-4970-cb17-a780ca53c68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101452, 101452)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 — Create a DataLoader\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RgD5fg4Y6OE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "centers_t = torch.tensor(centers, dtype=torch.long)\n",
        "targets_t = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "dataset = tud.TensorDataset(centers_t, targets_t)\n",
        "loader  = tud.DataLoader(dataset, batch_size=4096, shuffle=True, drop_last=False)\n",
        "len(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjkrqil_6LAt",
        "outputId": "ccc38011-8ad5-496e-c3eb-f21d938031fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101452"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 — Define the Skip-gram model\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vdQeF13U6lS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture is :\n",
        "Embedding(V, D) → Linear(D, V) → CrossEntropyLoss.\n",
        "It learns embeddings for each word (input layer) and output weights for predicting context words."
      ],
      "metadata": {
        "id": "OGSK6dlb6sO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.emb  = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.out  = nn.Linear(embed_dim, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, center_ids):      # (batch,)\n",
        "        e = self.emb(center_ids)        # (batch, D)\n",
        "        logits = self.out(e)            # (batch, V)\n",
        "        return logits\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "embed_dim = 100\n",
        "skipgram = SkipGram(vocab_size, embed_dim).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(skipgram.parameters(), lr=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "id": "HKZLBs-a6r-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 — Train the model\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We loop through the dataset in batches.\n",
        "Each epoch prints the average loss to monitor convergence."
      ],
      "metadata": {
        "id": "u3ob3wEZ7hMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram.train()\n",
        "epochs = 20\n",
        "for ep in range(1, epochs+1):\n",
        "    running = 0.0\n",
        "    for c_batch, t_batch in loader:\n",
        "        c_batch = c_batch.to(device)\n",
        "        t_batch = t_batch.to(device)\n",
        "\n",
        "        logits = skipgram(c_batch)\n",
        "        loss = criterion(logits, t_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running += loss.item()\n",
        "    print(f\"Epoch {ep}/{epochs} - avg loss: {running/len(loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhs7h-On6gB6",
        "outputId": "417cef56-73e5-4fe1-8c50-3deed1dbb2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - avg loss: 5.2914\n",
            "Epoch 2/20 - avg loss: 5.2790\n",
            "Epoch 3/20 - avg loss: 5.2660\n",
            "Epoch 4/20 - avg loss: 5.2534\n",
            "Epoch 5/20 - avg loss: 5.2414\n",
            "Epoch 6/20 - avg loss: 5.2294\n",
            "Epoch 7/20 - avg loss: 5.2176\n",
            "Epoch 8/20 - avg loss: 5.2064\n",
            "Epoch 9/20 - avg loss: 5.1962\n",
            "Epoch 10/20 - avg loss: 5.1857\n",
            "Epoch 11/20 - avg loss: 5.1751\n",
            "Epoch 12/20 - avg loss: 5.1649\n",
            "Epoch 13/20 - avg loss: 5.1561\n",
            "Epoch 14/20 - avg loss: 5.1468\n",
            "Epoch 15/20 - avg loss: 5.1371\n",
            "Epoch 16/20 - avg loss: 5.1280\n",
            "Epoch 17/20 - avg loss: 5.1197\n",
            "Epoch 18/20 - avg loss: 5.1105\n",
            "Epoch 19/20 - avg loss: 5.1021\n",
            "Epoch 20/20 - avg loss: 5.0939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 — Find the most similar words (cosine similarity)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "We inspect the learned embedding space to find words that are close to each other semantically."
      ],
      "metadata": {
        "id": "i0Y48B1G8nkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "def top_k_similar_skipgram(word, k=10):\n",
        "    if word not in word2idx: return []\n",
        "    with torch.no_grad():\n",
        "        E = skipgram.emb.weight.detach()                 # (V, D)\n",
        "        E = E / (E.norm(p=2, dim=1, keepdim=True) + 1e-9)\n",
        "        v = E[word2idx[word]]                            # (D,)\n",
        "        sims = torch.mv(E, v)                            # (V,)\n",
        "        vals, idxs = torch.topk(sims, k+1)               # includes the word itself\n",
        "        idxs = [i for i in idxs.tolist() if i != word2idx[word]][:k]\n",
        "        return [(idx2word[i], float(sims[i])) for i in idxs]\n",
        "\n",
        "\n",
        "print(top_k_similar_skipgram(\"man\", 10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2rTbccQ7mDk",
        "outputId": "25df3410-2173-45c4-8dbc-91263d370544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('carelessly', 0.41916146874427795), ('begot', 0.38257426023483276), ('pox', 0.3682824969291687), ('speedy', 0.3566665053367615), ('yea', 0.3491438031196594), ('dishclout', 0.3397133946418762), ('duellist', 0.33793193101882935), ('fairest', 0.3370053768157959), ('house', 0.33597180247306824), ('blessed', 0.3299347460269928)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6 — Compare CBOW vs Skip-gram\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hvQFcyyj9NXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_similar_cbow(word, k=10):\n",
        "    if word not in word2idx: return []\n",
        "    with torch.no_grad():\n",
        "        E = word2vec_cbow.embeddings.weight.detach()\n",
        "        E = E / (E.norm(p=2, dim=1, keepdim=True) + 1e-9)\n",
        "        v = E[word2idx[word]]\n",
        "        sims = torch.mv(E, v)\n",
        "        vals, idxs = torch.topk(sims, k+1)\n",
        "        idxs = [i for i in idxs.tolist() if i != word2idx[word]][:k]\n",
        "        return [(idx2word[i], float(sims[i])) for i in idxs]\n",
        "\n",
        "\n",
        "queries = [\"man\", \"romeo\", \"juliet\", \"love\"]\n",
        "for q in queries:\n",
        "    print(f\"\\n== {q.upper()} ==\")\n",
        "    print(\"CBOW     :\", [w for w,_ in top_k_similar_cbow(q, 10)])\n",
        "    print(\"Skip-gram:\", [w for w,_ in top_k_similar_skipgram(q, 10)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iIBddA29SB2",
        "outputId": "b893421c-9f22-439c-d59a-f5d5cc1b7efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== MAN ==\n",
            "CBOW     : ['tainted', 'toad', 'unadvis', 'conjur', 'sparkling', 'obscur', 'departed', 'mood', 'measure', 'purple']\n",
            "Skip-gram: ['carelessly', 'begot', 'pox', 'speedy', 'yea', 'dishclout', 'duellist', 'fairest', 'house', 'blessed']\n",
            "\n",
            "== ROMEO ==\n",
            "CBOW     : ['unsavoury', 'us', 'canopy', 'fourteen', 'soles', 'familiar', 'bleeds', 'coz', 'woes', 'vial']\n",
            "Skip-gram: ['midwife', 'pleasure', 'montague', 'usest', 'tiberio', 'brawling', 'heaviness', 'blazon', 'runagate', 'maskers']\n",
            "\n",
            "== JULIET ==\n",
            "CBOW     : ['lies', 'weraday', 'away', 'crow', 'protest', 'faithful', 'leaving', 'closely', 'couch', 'scars']\n",
            "Skip-gram: ['goodman', 'daughters', 'woful', 'affections', 'prostrate', 'commend', 'empty', 'haviour', 'dull', 'grubs']\n",
            "\n",
            "== LOVE ==\n",
            "CBOW     : ['henceforth', 'sea', 'feeling', 'wind', 'elflocks', 'because', 'spill', 'riddling', 'ladyship', 'lo']\n",
            "Skip-gram: ['direct', 'hoar', 'moderately', 'deceiv', 'jewel', 'ropery', 'o', 'intended', 'canopy', 'importun']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7 — Interpretation\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6-Du1dA39WlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing CBOW and Skip-gram\n",
        "\n",
        "- **CBOW (Continuous Bag-of-Words)** predicts the *center word* given surrounding *context words*.  \n",
        "- **Skip-gram** does the opposite: it predicts *context words* given a *center word*.  \n",
        "- Both use embeddings, but their training objectives differ.\n",
        "\n",
        "**Observations:**\n",
        "- The Skip-gram model tends to capture *rare words* and finer semantic relations better.  \n",
        "- CBOW usually trains faster and produces smoother embeddings for *frequent words*.  \n",
        "- The cosine neighbors for both models often overlap (e.g., *“man”* → *“woman”, “lord”, “gentleman”*).  \n",
        "- Skip-gram sometimes produces more specific or asymmetric relationships (context-driven).\n",
        "\n",
        "**Conclusion:**  \n",
        "Both models learn meaningful vector representations.  \n",
        "Skip-gram is more powerful for detailed semantics, while CBOW is computationally lighter.\n"
      ],
      "metadata": {
        "id": "uXbv78CB9ghP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # *3- Using FastText*"
      ],
      "metadata": {
        "id": "0v-6WYY397iM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 — Load a pretrained FastText model\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U6XqV5s19_dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install fasttext-wheel\n",
        "\n",
        "import fasttext, fasttext.util\n",
        "fasttext.util.download_model('en', if_exists='ignore')   # downloads cc.en.300.bin.gz\n",
        "!gunzip -f cc.en.300.bin.gz\n",
        "\n",
        "ft = fasttext.load_model('cc.en.300.bin')\n",
        "print(\"FastText loaded. Vector size:\", ft.get_dimension())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoI5hvZbFrR7",
        "outputId": "a20f9083-926d-4a3f-8dd2-125983314916"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText loaded. Vector size: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 — Quick sanity checks\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We inspect a few raw vectors and norms to confirm the model is usable.\n"
      ],
      "metadata": {
        "id": "Jbz0eelrS9V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vector dim:\", ft.get_dimension())\n",
        "vec_king = ft.get_word_vector(\"king\")\n",
        "print(\"First 10 dims of 'king':\", vec_king[:10])\n",
        "print(\"L2 norm of 'king':\", float((vec_king**2).sum()**0.5))\n"
      ],
      "metadata": {
        "id": "uzXbeK48ARzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ed194b-1858-44f3-cb08-ce4a1618da73"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector dim: 300\n",
            "First 10 dims of 'king': [-0.02636429 -0.04383384 -0.05224613  0.02497659  0.15994655  0.0049898\n",
            "  0.00251637 -0.01627121 -0.06621356 -0.00167889]\n",
            "L2 norm of 'king': 1.5576002597808838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 — Nearest neighbors\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We list the top-k nearest neighbors (cosine similarity) for a set of probe words.\n"
      ],
      "metadata": {
        "id": "jMk-xvTSTRNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ft_analogy(a: str, b: str, c: str, k: int = 10):\n",
        "    # Returns list of (similarity, word) for vector a - b + c\n",
        "    return ft.get_analogies(a, b, c, k)\n",
        "\n",
        "print(\"Analogy: paris - france + germany\")\n",
        "for sim, w in ft_analogy(\"paris\", \"france\", \"germany\", 10):\n",
        "    print(f\"{w:>18s}   {sim:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nteo0T7aTBSd",
        "outputId": "50edd586-e4ed-40fe-9d3a-d3f46a2248c8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy: paris - france + germany\n",
            "            berlin   0.689\n",
            "            munich   0.688\n",
            "           austria   0.636\n",
            "        dusseldorf   0.622\n",
            "         frankfurt   0.621\n",
            "            vienna   0.620\n",
            "         amsterdam   0.618\n",
            "           leipzig   0.617\n",
            "          freiburg   0.610\n",
            "          hannover   0.607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 — Word analogy: *paris − france + germany*\n",
        "We compute the composed vector **v = paris − france + germany** and retrieve the top-10 closest words.\n"
      ],
      "metadata": {
        "id": "9As86s40TZng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ft_analogy(a: str, b: str, c: str, k: int = 10):\n",
        "    # Returns list of (similarity, word) for vector a - b + c\n",
        "    return ft.get_analogies(a, b, c, k)\n",
        "\n",
        "print(\"Analogy: paris - france + germany\")\n",
        "for sim, w in ft_analogy(\"paris\", \"france\", \"germany\", 10):\n",
        "    print(f\"{w:>18s}   {sim:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zUUtufdTWnE",
        "outputId": "8bbed9a1-e0d0-4ace-caae-22eb1277d96c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy: paris - france + germany\n",
            "            berlin   0.689\n",
            "            munich   0.688\n",
            "           austria   0.636\n",
            "        dusseldorf   0.622\n",
            "         frankfurt   0.621\n",
            "            vienna   0.620\n",
            "         amsterdam   0.618\n",
            "           leipzig   0.617\n",
            "          freiburg   0.610\n",
            "          hannover   0.607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 — OOV (out-of-vocabulary) robustness\n",
        "FastText composes vectors from character n-grams, so even unseen tokens get reasonable embeddings.\n"
      ],
      "metadata": {
        "id": "hbqMNrJvVABq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_neighbors(\"unseenword123\", 5)\n",
        "show_neighbors(\"shakespearishness\", 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVA_SJa2UJps",
        "outputId": "1b512330-1275-4bbf-f0b0-9617e7a26554"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top-5 neighbors (FastText) for 'unseenword123':\n",
            "crescendosexibloguerobateyabsorbersexiindesignabledinerolatifundiosexibrezarcularsutesexirapoplinbrezarcorrentosoVd.lazadareflejoreglafeministabrezarchuzasexiouttiqueblogueroin   0.507\n",
            "deblogueroreflejoantecedentesexitlacuachebateysuteindesignableabsorbersexilatifundiosexibrezarsutemultiétnicosexiplinrapobrezarcorrentosoVd.lazadafisiochillidomabrezarsico-chuzaoutcolodrablogueroin   0.500\n",
            "QQFZAAEACwAAAAAGQASAAAIjgAJCBQIoGDBgQgTKiwooGHDgwshDgTgsOLDhAAGaAQwUYBBhx85EtS4cWLGjR5JSjxZkgDFkwwLohTJUqTLlANiwvQ4seVNjwwfBoVokKjFo0Jlksz506NFiklZtoQKFSjIoktLVv1YsahSn1WP0vzq02VYoAjJMsVYVKHZrDbdupW6Vq5cunHtRjQoMCAAIfkECRQABAAsCQADAAQABAAACAsABQgkILCgwYEBAQAh   0.455\n",
            "CrônicasEsdrasNeemiasEsterJóSalmosProvérbiosEclesiastesCânticosIsaíasJeremiasLamentaçõesEzequielDanielOséiasJoelAmósObadiasJonasMiquéiasNaumHabacuqueSofoniasAgeuZacariasMalaquiasNovo   0.448\n",
            "DEky4M0BSpUOTPnSpkuL5I0GTSnRI4jMepcaFAoxIoFnX5kmJQk1aYvr2odGBAAIfkECQoABAAsCQAAABAAEgAACGcAARAYSLCgQQEABBokkFAhAQEQHQ4EMKCiQogRCVKsOOAiRocbLQ7EmJEhR4cfEWoUOTFhRIUNE44kGZOjSIQfG9rsyDCnzp0AaMYMyfNjS6JFZWpEKlDiUqALJ0KNatKmU4NDBwYEACH5BAkKAAQALAkAAAAQABIAAAhpAAEQGEiQIICDBAUgLEgAwICHAgkImBhxoMOHAyJOpGgQY8aBGxV2hJgwZMWLFTcCUIjwoEuLBym69PgxJMuDNAUqVDkz50qZLi   0.447\n",
            "\n",
            "Top-5 neighbors (FastText) for 'shakespearishness':\n",
            "airplanealertapp-downloadarrow-downarrow-expandarrow-leftarrow-right-alternatearrow-rightarrow-upattractionbadgeballoonsbarcodebellbookbuildingcalendarcameracarcartcash-backchairchat-dotschatcheck-circlecheckboxclosecomputercreatecruiseemptybadgeenvelope-open-outlineenvelope-openenvelopefacebookfingerflowerfoodfootballgeargift-cardgiftgridguitarhealthheart-outlinehearthome-gardeninfojewellifetime-cashbacklipsticklocationlockmapmedalmenuminus-circlemoneynewsomnichannelpacifierpaperclippawphoneplayplugplusprintpromotedquestion-markrebatermn-rsearchshareshirtshoeslidersstar-outlinestarstopwatchstoretag-addtagthumbs-downthumbs-uptoytrophyuserwatchx   0.444\n",
            "crescendosexibloguerobateyabsorbersexiindesignabledinerolatifundiosexibrezarcularsutesexirapoplinbrezarcorrentosoVd.lazadareflejoreglafeministabrezarchuzasexiouttiqueblogueroin   0.441\n",
            "worldBFHinditranslatetranslationmoobspracticeracismtranslateterrorismcatvaleracismbespokeaffectcentreBFHinditranslatetranslationchappalBFHindiTamilTelugutranslationMalaytranslateTamiltranslationbaconUrdutranslatetranslationEnglishsentencetranslatetranslationEnglishsowpost-truthBFracismsupercalifragilisticexpialidocioustranslateHindiSign   0.438\n",
            "MedicineAnomaliesAnti-vaxAntiscienceAstrologyBelief   0.438\n",
            "groothiuseconomicseconomyeducationegalitarianismeliot   0.437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example :\n",
        "We query two made-up or rare tokens:\n",
        "- `\"unseenword123\"` a totally invented word  \n",
        "- `\"shakespearishness\"` a creative morphological form not present in the training corpus\n",
        "\n",
        "FastText can still return semantically related words for both, showing that it generalizes to unseen forms by analyzing subword patterns."
      ],
      "metadata": {
        "id": "1HKDs7-nVySw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WdmhrLL_VMpf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}